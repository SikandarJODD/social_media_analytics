{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Homework 8 - Image Analysis\n",
        "\n",
        "This notebook provides some skeleton code to get you started on the homework. Add in your own code and markdown cells to answer the homework questions. If you want to submit the notebook as a PDF, make sure your code and markdowns are clear and concise to make grading easy for the TAs.\n",
        "\n",
        "This notebook can be opened in Colab\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/zlisto/social_media_analytics/blob/main/HW7_ImageAnalysis.ipynb)\n",
        "\n",
        "\n",
        "Before starting, select \"Runtime->Factory reset runtime\" to start with your directories and environment in the base state.\n",
        "\n",
        "If you want to save changes to the notebook, select \"File->Save a copy in Drive\" from the top menu in Colab. This will save the notebook in your Google Drive.\n",
        "\n",
        "For all plots, make sure your axes have nice labels with easy to read fontsizes, otherwise points will be deducted.\n",
        "\n",
        "The OpenAI API calls to do this homework cost approximately <insert cost>.\n"
      ],
      "metadata": {
        "id": "CNJF9PVslw5Y"
      },
      "id": "CNJF9PVslw5Y"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clones, Installs, and Imports"
      ],
      "metadata": {
        "id": "utVwd-MCuE_d"
      },
      "id": "utVwd-MCuE_d"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nzFWTbuarc62"
      },
      "id": "nzFWTbuarc62",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem 1. (31 points) Basic Image Analysis"
      ],
      "metadata": {
        "id": "sv6-tXg99Gen"
      },
      "id": "sv6-tXg99Gen"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (5 points) 1. Load Image\n",
        "\n",
        "Load the image with file name `\"data/image_compressed_leomessi/3291736544082520189_427553890_small.jpeg\"` and display it. Convert the image to an appropriate `image_url` for Vision (GPT-4V) and add it to a list `image_urls`. Print out the list `image_urls` so we know you did it right. Also, display the image so you can see how cool it looks."
      ],
      "metadata": {
        "id": "2uo6_BQXuddW"
      },
      "id": "2uo6_BQXuddW"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CcOEFpCMi9fS"
      },
      "id": "CcOEFpCMi9fS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (5 points) 2. Recommendations to Enhance Image\n",
        "\n",
        "Use Vision to provide recommendations to make the image more engaging for Instagram.  Tell it who the target audience is for this image.  Call the recommendation a string `recommendation`.  Print out `recommendation` using `tr.fill`."
      ],
      "metadata": {
        "id": "9_pak_rVvGtk"
      },
      "id": "9_pak_rVvGtk"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "d2IE16t6i-U_"
      },
      "id": "d2IE16t6i-U_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (4 points) 3. Describe Image\n",
        "\n",
        "Use Vision to describe the original image and call this `image_description`.  Print out `image_description` with `tr.fill`."
      ],
      "metadata": {
        "id": "fX5CXW3yuEBj"
      },
      "id": "fX5CXW3yuEBj"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "94Ih7nhjoPTC"
      },
      "id": "94Ih7nhjoPTC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (5 points) 4. Enhanced Image\n",
        "\n",
        "Create a `prompt` that combines `image_description` with the recommendations from the previous part and have DALL-E 3 generate the enhanced image.  Display your enhanced image using the `display_image_url` function so the TAs can see it."
      ],
      "metadata": {
        "id": "SFploxbiLXlR"
      },
      "id": "SFploxbiLXlR"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ym4_PYprjAXe"
      },
      "id": "ym4_PYprjAXe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (6 points) 5. Generate Caption for Image\n",
        "Go to the Instagram account for leomessi and copy a caption for one of his images and create a string called `caption_example` that equals this caption.  Then feed the generated image to Vision and have it generate an Instagram caption for it using the `caption_example` as a style and tone guide.  Print out the generated caption using `tr.fill`."
      ],
      "metadata": {
        "id": "QsApFxtRx9aB"
      },
      "id": "QsApFxtRx9aB"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PCrx6ij0jBpu"
      },
      "id": "PCrx6ij0jBpu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (6 points) 6. Compare Images\n",
        "\n",
        "Give Vision the original image and the generated image as inputs and ask it to explain which image will be more engaging on Instagram for an audience of soccer fans.  Print out the explanation using `tr.fill` so it is easy to read.\n"
      ],
      "metadata": {
        "id": "XN7QSQRsxJpu"
      },
      "id": "XN7QSQRsxJpu"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G4TCZMA9jDB7"
      },
      "id": "G4TCZMA9jDB7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem 2. (30 points) Cluster Analysis\n",
        "\n"
      ],
      "metadata": {
        "id": "qsq390FDxYAF"
      },
      "id": "qsq390FDxYAF"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (3 points) 1. Load Image Data\n",
        "\n",
        "Load the file `data/leomessi_embedding.csv` into a dataframe `df`.  Print out the head of the dataframe.  You should see the image path and the UMAP coordinates for each image."
      ],
      "metadata": {
        "id": "_OVrRX1sFU8E"
      },
      "id": "_OVrRX1sFU8E"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ppxgYBcvjFUT"
      },
      "id": "ppxgYBcvjFUT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (8 points) 2. Cluster Images\n",
        "\n",
        "Apply K-means clustering to the UMAP embedding with `k=4` clusters, `n_init='auto'` and `random_state = 0`.  Add these labels to `df` in a column called `cluster`.  Make a `countplot` of the `cluster` column."
      ],
      "metadata": {
        "id": "PxDC6v648yUW"
      },
      "id": "PxDC6v648yUW"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mNJ4Q2P5jGMa"
      },
      "id": "mNJ4Q2P5jGMa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (8 points) 3. Analyze Clusters\n",
        "\n",
        "We will now use Vision to analyze each cluster.\n",
        "Do the following for each cluster in `df`.\n",
        "Sample 4 random images from each cluster and give them to Vision with `instructions` telling it to describe the common theme in the cluster.  Display each sampled image and print out the cluster description (use the `tr.fill` function)."
      ],
      "metadata": {
        "id": "-Q08Rb4ICrqu"
      },
      "id": "-Q08Rb4ICrqu"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "856U98BnElLK"
      },
      "id": "856U98BnElLK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (6 points) 4. New Content Ideas\n",
        "\n",
        "Take a sample of 4 images from one of the clusters and give them to Vision and ask it to generate three ideas for new content this account could post in a similar style.  Ask it to return the answer as an HTML string and dislay the response with the `display` and `HTML` functions."
      ],
      "metadata": {
        "id": "O9wjPR_i6ckx"
      },
      "id": "O9wjPR_i6ckx"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yvBlvwEyjgbJ"
      },
      "id": "yvBlvwEyjgbJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (5 points) 5. Generate Image From Idea\n",
        "\n",
        "Take one of the image ideas from the previous problem and generate an image from it using DALL-E 3.  Display the image using the `display_image_url` function."
      ],
      "metadata": {
        "id": "8YhvEuK84zBH"
      },
      "id": "8YhvEuK84zBH"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DInkjyfzo9jn"
      },
      "id": "DInkjyfzo9jn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem 3 (18 points) Tweeting a Reaction to an Image\n"
      ],
      "metadata": {
        "id": "b6ECdt2Qk4x5"
      },
      "id": "b6ECdt2Qk4x5"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (5 points) 1. Load Image\n",
        "\n",
        "Load the image with file name `\"data/image_compressed_cristiano/1002943321108551605_173560420_small.jpeg\"` and display it. Convert the image to an appropriate `image_url` for Vision and add it to a list `image_urls`. Print out the list `image_urls` so we know you did it right.  Also display the image so you can see how cool it looks.\n"
      ],
      "metadata": {
        "id": "8NK2R5MGtSNV"
      },
      "id": "8NK2R5MGtSNV"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qtON4cBi9NXO"
      },
      "id": "qtON4cBi9NXO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (7 points) 2. Describe Twitter User\n",
        "\n",
        "Write a `user_description` of a Twitter user who will see this image and react to it.  Be creative :).  Then give Vision `instructions` that tell it to provide more details about the tweeting style of this user.  Call this output string `tweet_style`.  Print out `tweet_style` using `tr.fill`."
      ],
      "metadata": {
        "id": "YJ_O9jMWtZtS"
      },
      "id": "YJ_O9jMWtZtS"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_yjPZ_BJ9N6N"
      },
      "id": "_yjPZ_BJ9N6N",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (6 points) 3. Tweet Reaction to Image\n",
        "\n",
        "Use Vision to write a tweet in the style of the user from the previous part to the image in `image_urls` from part 1.  Print out your instructions prompt and the tweet reaction using `tr.fill`.  Also display the orignal image.\n"
      ],
      "metadata": {
        "id": "WFzhZjkytev-"
      },
      "id": "WFzhZjkytev-"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DUwDiQwOo7Dp"
      },
      "id": "DUwDiQwOo7Dp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem 4. (21 points) Generate Text Narration of a Video"
      ],
      "metadata": {
        "id": "xAM0opBOxk2d"
      },
      "id": "xAM0opBOxk2d"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (6 points) 1. Load Frames From Video\n",
        "\n",
        "Load the video located at `\"data/videos/leomessi - Argentina.mp4\"` and convert it into a list of images called `base64Frames`.  Print out the length of `base64Frames`"
      ],
      "metadata": {
        "id": "h0AD-xSD5Vv1"
      },
      "id": "h0AD-xSD5Vv1"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wLDTk6xC9Paw"
      },
      "id": "wLDTk6xC9Paw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (3 points) 2. Sample Frames\n",
        "\n",
        "Sample every 60 frames from the video and call this array `base64Frames_samples`.  Print out the length of  `base64Frames_samples`.  "
      ],
      "metadata": {
        "id": "thHYHmBT5bRQ"
      },
      "id": "thHYHmBT5bRQ"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RKXJETqdo5iW"
      },
      "id": "RKXJETqdo5iW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (3 points) 3. Narration Length\n",
        "\n",
        "A human speaks 200 words per minute.  Using this, calculate `nwords_max`, the maximum number of words in the narration for the video.  Print out the duration of the video in seconds and `nwords_max`."
      ],
      "metadata": {
        "id": "jXLKOY-k7H4F"
      },
      "id": "jXLKOY-k7H4F"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pf5_qnP29RKh"
      },
      "id": "pf5_qnP29RKh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (6 points) 4. Create Text of Narration for Video\n",
        "\n",
        "Give Vision  `base64Frames_samples` and some `instructions` to generate the narration text for the video.  You can choose the style and focus of the narrative, but it should relate to the video content.\n",
        "\n",
        " Make sure the narration has fewer than `nwords_max` words.  Print out the narration (use `tr.fill`)."
      ],
      "metadata": {
        "id": "S6p4xkQN5ouL"
      },
      "id": "S6p4xkQN5ouL"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NtI-wgPL9R08"
      },
      "id": "NtI-wgPL9R08",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (3 points) 5. Word Count of Narration\n",
        "\n",
        "Print out the number of words in the narration.  Make sure it is less than `nwords_max`. If it does not, generate another narration."
      ],
      "metadata": {
        "id": "dN7q-iQp7c8L"
      },
      "id": "dN7q-iQp7c8L"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QOpwdWr6o2F6"
      },
      "id": "QOpwdWr6o2F6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (0 points) 6. Add Narration to Video\n",
        "\n",
        "If you like, you can generate the audio for the narration and add it to the video using a video editing software.  If you think the video is really compelling, email it to the Professor and if he agrees, he will highlight it during lecture."
      ],
      "metadata": {
        "id": "fKyHGbTp3mcb"
      },
      "id": "fKyHGbTp3mcb"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T7VPcuwU9csO"
      },
      "id": "T7VPcuwU9csO",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}