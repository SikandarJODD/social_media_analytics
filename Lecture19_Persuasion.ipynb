{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "uM_Hk2DxRw32",
   "metadata": {
    "id": "uM_Hk2DxRw32"
   },
   "source": [
    "# Lecture 19 Persuasion\n",
    "\n",
    "This notebook will let you generate images using the OpenAI images API.\n",
    "\n",
    "Below is the overview of this notebook.\n",
    "\n",
    "<ol type = 1>\n",
    "  <li> Generate targeted content based on user descriptions </li>\n",
    "  <li> Generate targeted content based on user tweets </li>\n",
    "  <li> Generate targeted video content based on user descriptions or tweets </li>\n",
    "</ol>\n",
    "\n",
    "This notebook can be opened in Colab\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/zlisto/social_media_analytics/blob/main/Lecture19_Persuasion.ipynb)\n",
    "\n",
    "Before starting, select \"Runtime->Factory reset runtime\" to start with your directories and environment in the base state.\n",
    "\n",
    "If you want to save changes to the notebook, select \"File->Save a copy in Drive\" from the top menu in Colab.  This will save the notebook in your Google Drive.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "utVwd-MCuE_d",
   "metadata": {
    "id": "utVwd-MCuE_d"
   },
   "source": [
    "# Clones, Installs, and Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qxwez1L-j2mS",
   "metadata": {
    "id": "qxwez1L-j2mS"
   },
   "source": [
    "## Clone Repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0288fd",
   "metadata": {
    "id": "cb0288fd"
   },
   "outputs": [],
   "source": [
    "# Clone GitHub repository\n",
    "!git clone https://github.com/zlisto/social_media_analytics\n",
    "\n",
    "import os\n",
    "os.chdir(\"social_media_analytics\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sFPHN9_Jj1IR",
   "metadata": {
    "id": "sFPHN9_Jj1IR"
   },
   "source": [
    "## Installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c55003",
   "metadata": {
    "id": "94c55003"
   },
   "outputs": [],
   "source": [
    "# Install requirements\n",
    "!pip install openai -q\n",
    "!pip install umap-learn -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Z3Gq-iC8j5Gz",
   "metadata": {
    "id": "Z3Gq-iC8j5Gz"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81d6de4",
   "metadata": {
    "id": "e81d6de4"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import textwrap as tr\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "import os\n",
    "import time\n",
    "import ast\n",
    "import json\n",
    "from IPython.display import Image,display, HTML, Audio\n",
    "import random\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "import base64\n",
    "import requests\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image as PILImage\n",
    "\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import cv2  # We're using OpenCV to read video, to install !pip install opencv-python\n",
    "import requests\n",
    "import os\n",
    "\n",
    "import openai\n",
    "import tqdm\n",
    "from tqdm import tqdm_notebook\n",
    "tqdm_notebook().pandas()\n",
    "from umap import UMAP\n",
    "from sklearn.decomposition import PCA\n",
    "import math\n",
    "\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "plt.rcParams['figure.figsize'] = [8, 6]  # Width=8 inches, height=6 inches\n",
    "plt.rc('axes', titlesize=18)\n",
    "plt.rc('axes', labelsize=18)\n",
    "plt.rc('xtick', labelsize=14)\n",
    "plt.rc('ytick', labelsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc0f2c2",
   "metadata": {
    "id": "abc0f2c2"
   },
   "outputs": [],
   "source": [
    "#set your OpenAI API key as a string\n",
    "OPENAI_API_KEY = ''\n",
    "\n",
    "client = openai.Client(api_key=OPENAI_API_KEY)\n",
    "#Pick your text model\n",
    "#MODEL = \"gpt-3.5-turbo-1106\"\n",
    "MODEL = \"gpt-4-1106-preview\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "w74A9ZCO89jn",
   "metadata": {
    "id": "w74A9ZCO89jn"
   },
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ZIM_hzy88IO",
   "metadata": {
    "id": "2ZIM_hzy88IO"
   },
   "outputs": [],
   "source": [
    "def get_embedding(text, model=\"text-embedding-3-large\"):\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    return client.embeddings.create(input = [text], model=model).data[0].embedding\n",
    "\n",
    "def get_completion(prompt, instructions, client, model=\"gpt-3.5-turbo\",\n",
    "                   output_type = 'text'):\n",
    "  '''Get a text completion from the OpenAI API'''\n",
    "  completion = client.chat.completions.create(\n",
    "                model=model,\n",
    "                response_format={ \"type\": output_type},\n",
    "                messages=[\n",
    "                  {\"role\": \"system\", \"content\": instructions},\n",
    "                  {\"role\": \"user\", \"content\": prompt}\n",
    "                ]\n",
    "              )\n",
    "  response =completion.choices[0].message.content\n",
    "\n",
    "  return response\n",
    "\n",
    "def generate_image(prompt = \"Draw a cute bunny\", model = \"dall-e-3\"):\n",
    "  '''Generates an image using the OpenAI API'''\n",
    "\n",
    "  response_img = client.images.generate(\n",
    "    model= model,\n",
    "    prompt=prompt,\n",
    "    size=\"1024x1024\",\n",
    "    quality=\"standard\",\n",
    "    n=1,\n",
    "  )\n",
    "  time.sleep(1)\n",
    "  image_url = response_img.data[0].url\n",
    "  revised_prompt = response_img.data[0].revised_prompt\n",
    "\n",
    "  return image_url, revised_prompt\n",
    "\n",
    "def generate_image_description(image_urls, instructions):\n",
    "  '''Generates a description of a list of image_urls using the OpenAI Vision API'''\n",
    "  PROMPT_MESSAGES = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [{\"type\": \"text\",\"text\":instructions},\n",
    "            *map(lambda x: {\"type\":\"image_url\",\"image_url\": x}, image_urls),\n",
    "        ],\n",
    "    },\n",
    "  ]\n",
    "  params = {\n",
    "      \"model\": \"gpt-4-vision-preview\",\n",
    "      \"messages\": PROMPT_MESSAGES,\n",
    "      \"max_tokens\": 1000,\n",
    "  }\n",
    "\n",
    "  response= client.chat.completions.create(**params)\n",
    "\n",
    "\n",
    "  image_description = response.choices[0].message.content\n",
    "  return image_description\n",
    "\n",
    "def encode_image(image_path):\n",
    "  '''Encodes an image to base64'''\n",
    "  with open(image_path, \"rb\") as image_file:\n",
    "    return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "def display_image_url(image_url, width = 500, height = 500):\n",
    "  '''Display the image located at image_url so it remains in the notebook\n",
    "  even after the link dies '''\n",
    "  response = requests.get(image_url)\n",
    "  image_data = response.content\n",
    "  # Encoding the image data as base64\n",
    "  base64_image = base64.b64encode(image_data).decode('utf-8')\n",
    "  # Generating HTML to display the image\n",
    "  html_code = f'<img src=\"data:image/jpeg;base64,{base64_image}\" width=\"{width}\" height=\"{height}\"/>'\n",
    "  # Displaying the image in the notebook\n",
    "  display(HTML(html_code))\n",
    "  return html_code\n",
    "\n",
    "def display_tweet(text='life is good', screen_name='zlisto'):\n",
    "    display_html = f'''\n",
    "    <!DOCTYPE html>\n",
    "    <html>\n",
    "    <head>\n",
    "        <style>\n",
    "            .tweet {{\n",
    "                background-color: white;\n",
    "                color: black;\n",
    "                border: 1px solid #e1e8ed;\n",
    "                border-radius: 10px;\n",
    "                padding: 20px;\n",
    "                max-width: 500px;\n",
    "                margin: 20px auto;\n",
    "                font-family: 'Helvetica Neue', Helvetica, Arial, sans-serif;\n",
    "                box-shadow: 0px 0px 10px rgba(0,0,0,0.1);\n",
    "            }}\n",
    "            .user strong {{\n",
    "                color: #1da1f2;\n",
    "            }}\n",
    "            .tweet-text p {{\n",
    "                margin: 0;\n",
    "                line-height: 1.5;\n",
    "            }}\n",
    "        </style>\n",
    "    </head>\n",
    "    <body>\n",
    "        <div class=\"tweet\">\n",
    "            <div class=\"user\">\n",
    "                <strong>@{screen_name}</strong>\n",
    "            </div>\n",
    "            <div class=\"tweet-text\">\n",
    "                <p>{text}</p>\n",
    "            </div>\n",
    "        </div>\n",
    "    </body>\n",
    "    </html>\n",
    "    '''\n",
    "    display(HTML(display_html))\n",
    "    return display_html\n",
    "\n",
    "def display_IG(caption, image_url, screen_name='zlisto', profile_image_url = None):\n",
    "    response = requests.get(image_url)\n",
    "    image_data = response.content\n",
    "    # Encoding the image data as base64\n",
    "    base64_image = base64.b64encode(image_data).decode('utf-8')\n",
    "    # Generating HTML to display the image\n",
    "    image_url_local = f'data:image/jpeg;base64,{base64_image}'\n",
    "\n",
    "    ''' HTML template for displaying the image, screen name, and caption in an Instagram-like format'''\n",
    "\n",
    "    display_html = f\"\"\"\n",
    "    <style>\n",
    "        .instagram-post {{\n",
    "            border: 1px solid #e1e1e1;\n",
    "            border-radius: 3px;\n",
    "            width: 600px;\n",
    "            margin: 20px auto;\n",
    "            background-color: white;\n",
    "            font-family: 'Helvetica Neue', Helvetica, Arial, sans-serif;\n",
    "        }}\n",
    "        .instagram-header {{\n",
    "            padding: 14px;\n",
    "            border-bottom: 1px solid #e1e1e1;\n",
    "            display: flex;\n",
    "            align-items: center;\n",
    "        }}\n",
    "        .instagram-profile-pic {{\n",
    "            border-radius: 50%;\n",
    "            width: 32px;\n",
    "            height: 32px;\n",
    "            margin-right: 10px;\n",
    "        }}\n",
    "        .instagram-screen-name {{\n",
    "            font-weight: bold;\n",
    "            color: #262626;\n",
    "            text-decoration: none;\n",
    "            font-size: 14px;\n",
    "        }}\n",
    "        .instagram-image {{\n",
    "            max-width: 600px;\n",
    "            width: auto;\n",
    "            height: auto;\n",
    "            display: block;\n",
    "            margin: auto;\n",
    "        }}\n",
    "        .instagram-caption {{\n",
    "            padding: 10px;\n",
    "            font-size: 14px;\n",
    "            color: #262626;\n",
    "        }}\n",
    "        .instagram-footer {{\n",
    "            padding: 10px;\n",
    "            border-top: 1px solid #e1e1e1;\n",
    "        }}\n",
    "        .instagram-likes {{\n",
    "            font-weight: bold;\n",
    "            margin-bottom: 8px;\n",
    "        }}\n",
    "    </style>\n",
    "    <div class=\"instagram-post\">\n",
    "        <div class=\"instagram-header\">\n",
    "            <img src=\"{profile_image_url}\" alt=\"Profile picture\" class=\"instagram-profile-pic\">\n",
    "            <a href=\"#\" class=\"instagram-screen-name\">{screen_name}</a>\n",
    "        </div>\n",
    "        <img src=\"{image_url_local}\" alt=\"Instagram image\" class=\"instagram-image\">\n",
    "        <div class=\"instagram-caption\">\n",
    "            <a href=\"#\" class=\"instagram-screen-name\">{screen_name}</a> {caption}\n",
    "        </div>\n",
    "        <div class=\"instagram-footer\">\n",
    "            <div class=\"instagram-likes\">24 likes</div>\n",
    "            <!-- Include other footer content here -->\n",
    "        </div>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    display(HTML(display_html))\n",
    "    return display_html\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fLn249iztHg8",
   "metadata": {
    "id": "fLn249iztHg8"
   },
   "source": [
    "# Targeted Content for Synthetic Users\n",
    "\n",
    "We will create content that is designed to persuade sythethic users we create."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "QkcGo1Y2wsCp",
   "metadata": {
    "id": "QkcGo1Y2wsCp"
   },
   "source": [
    "## Describe Synthetic Users\n",
    "\n",
    "First we will describe the sythentic users we want to target.  Their descriptions are saved in a dataframe `df_targets`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "t2AGOrEnx-1L",
   "metadata": {
    "id": "t2AGOrEnx-1L"
   },
   "outputs": [],
   "source": [
    "targets = []\n",
    "\n",
    "targets.append('''Tauhid, a professor at Yale, is aa young male who\n",
    "has a PhD in computer science and\n",
    "loves AI, crypto, Marvel movies, especially Avengers Endgame, and\n",
    "hip hop, especially Jadakiss.''')\n",
    "\n",
    "targets.append('''Alex, from Santa Fe, New Mexico, embodies the region's\n",
    "cultural blend with shoulder-length, sun-lightened brown hair, often\n",
    "accessorized with a turquoise necklace. They wear a mix of traditional\n",
    "and modern eco-friendly clothing, reflecting Santa Fe's artistic and\n",
    "environmental values. Professionally, Alex might be an artist or gallery\n",
    "professional, deeply connected to the history and future of Southwestern\n",
    "art, and enjoys hiking and attending local festivals in their free time.''')\n",
    "\n",
    "targets.append('''Cheryl, a woman from Chicago. She’s got that urban,\n",
    "Windy City flair—confident and walking with purpose. Her style is a\n",
    "mix of high-street fashion with thrift shop finds; think a sleek blazer\n",
    "paired with vintage jeans. She's likely got headphones on, nodding to\n",
    "some Chance the Rapper, a local legend, as she navigates the crowded\n",
    "sidewalks. There’s an energy about her that’s a blend of ambition and\n",
    "a deep appreciation for the art and culture that’s etched into the\n",
    "very architecture of the city. She’s a professional, working at one of\n",
    "the city’s many startups, and after hours, you might find her at a\n",
    "poetry slam, an improv comedy show, or enjoying a deep-dish pizza with\n",
    "friends. Her vibe is very much Chicago: resilient, diverse, and ever-evolving.''')\n",
    "\n",
    "df_targets = pd.DataFrame({'description':targets})\n",
    "df_targets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "FkWrdC5_26h0",
   "metadata": {
    "id": "FkWrdC5_26h0"
   },
   "source": [
    "## Define the Persuasion Topic\n",
    "\n",
    "We choose the `topic` we want to persuade these users to support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "QPakgmTj28_d",
   "metadata": {
    "id": "QPakgmTj28_d"
   },
   "outputs": [],
   "source": [
    "topic = '''The government should provide student debt relief. '''\n",
    "\n",
    "print(tr.fill(topic))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jukr4wUq2l4M",
   "metadata": {
    "id": "jukr4wUq2l4M"
   },
   "source": [
    "## Create Targeted Tweets\n",
    "\n",
    "Choose your `content` to be a tweet.  Then use the `instructions` and the `description` of the user to create the content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tyd1DNjLt5xp",
   "metadata": {
    "id": "tyd1DNjLt5xp"
   },
   "outputs": [],
   "source": [
    "content = 'tweet'\n",
    "\n",
    "instructions = f'''You will be given a description of a target user.\n",
    "Convince them to support {topic} with a {content}.\n",
    "Dont directly mention the information about the target in the message.\n",
    "Be more subtle as that makes the persuasion more effective. '''\n",
    "\n",
    "for index,row in df_targets.iterrows():\n",
    "  description = row['description']\n",
    "  prompt = f'''User description:\\n{description}.'''\n",
    "  tweet = get_completion(prompt, instructions,client,MODEL)\n",
    "  df_targets.loc[index,'tweet'] = tweet\n",
    "  print(f\"\\n{tr.fill(description)}\\n\")\n",
    "  display_tweet(tweet)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kBerCPJ8jHnE",
   "metadata": {
    "id": "kBerCPJ8jHnE"
   },
   "source": [
    "## Create Targeted Instagram Posts\n",
    "\n",
    "Choose your `content` to be an Instagram image.  Then use the `instructions` and the `description` of the user to create the content (image and caption)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spKaOgf_jHN6",
   "metadata": {
    "id": "spKaOgf_jHN6"
   },
   "outputs": [],
   "source": [
    "content = \"description of an image to be posted to Instagram.\"\n",
    "\n",
    "instructions = f'''You will be given a description of a person.\n",
    "Convince them to support {topic} with a {content}.\n",
    "Dont directly mention the information about the target in the message.\n",
    "Be more subtle as that makes the persuasion more effective. '''\n",
    "\n",
    "for index, row in df_targets.iterrows():\n",
    "  description = row['description']\n",
    "  prompt = f'''User description:\\n{description}.'''\n",
    "\n",
    "  instructions_caption = f'''Write an Instagram caption for this image\n",
    "  that will persuade a person with description {description} to\n",
    "  support {topic} '''\n",
    "\n",
    "  #Chat-GPT\n",
    "  image_prompt = get_completion(prompt, instructions,client,MODEL)\n",
    "  #DALL-E 3\n",
    "  image_url, revised_prompt = generate_image(image_prompt)\n",
    "  #Vision\n",
    "  caption = generate_image_description(image_urls, instructions_caption)\n",
    "\n",
    "  print(f\"\\n{tr.fill(description)}\")\n",
    "  print(f\"\\n{tr.fill(image_prompt)}\")\n",
    "  display_IG(caption, image_url)\n",
    "\n",
    "  df_targets.loc[index,'image_prompt'] = image_prompt\n",
    "  df_targets.loc[index,'image_url'] = image_url\n",
    "  df_targets.loc[index,'caption'] = caption"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nLMfoJ61gQbc",
   "metadata": {
    "id": "nLMfoJ61gQbc"
   },
   "source": [
    "# Geometry of Users, Topic, and Targeted Content\n",
    "\n",
    "We can plot the embeddings of the topic, the user descriptions, and the targeted content to understand the geometry of the targeted content."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6OLcgmV81l4g",
   "metadata": {
    "id": "6OLcgmV81l4g"
   },
   "source": [
    "## Compute Embeddings of Topic, Targets, and Content\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "MT4Dv3fwunye",
   "metadata": {
    "id": "MT4Dv3fwunye"
   },
   "outputs": [],
   "source": [
    "df_targets['embedding_target'] = df_targets['description'].progress_apply(get_embedding)\n",
    "df_targets['embedding_content'] = df_targets['tweet'].progress_apply(get_embedding)\n",
    "\n",
    "v = get_embedding(topic)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7TZbe78w3F6J",
   "metadata": {
    "id": "7TZbe78w3F6J"
   },
   "source": [
    "## Compute Low-Dimensional Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718oyFdevXik",
   "metadata": {
    "id": "718oyFdevXik"
   },
   "outputs": [],
   "source": [
    "T = np.stack(df_targets['embedding_target'].values, axis = 0)\n",
    "C = np.stack(df_targets['embedding_content'].values, axis = 0)\n",
    "TC = np.vstack([T,C, [v]])\n",
    "\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "pca_embedding = pca.fit_transform(TC)\n",
    "\n",
    "umap = UMAP(n_components=2)\n",
    "umap_embedding = umap.fit_transform(TC)\n",
    "\n",
    "ntargets = len(df_targets)\n",
    "df_targets['target_pca_x'] = pca_embedding[0:ntargets,0]\n",
    "df_targets['target_pca_y'] = pca_embedding[0:ntargets:,1]\n",
    "\n",
    "df_targets['content_pca_x'] = pca_embedding[ntargets:2*ntargets,0]\n",
    "df_targets['content_pca_y'] = pca_embedding[ntargets:2*ntargets,1]\n",
    "\n",
    "df_targets['target_umap_x'] = umap_embedding[0:ntargets,0]\n",
    "df_targets['target_umap_y'] = umap_embedding[0:ntargets:,1]\n",
    "\n",
    "df_targets['content_umap_x'] = umap_embedding[ntargets:2*ntargets,0]\n",
    "df_targets['content_umap_y'] = umap_embedding[ntargets:2*ntargets,1]\n",
    "\n",
    "v_pca = pca_embedding[-1,:]\n",
    "\n",
    "v_umap = umap_embedding[-1,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "NlS9d_HG3Ix4",
   "metadata": {
    "id": "NlS9d_HG3Ix4"
   },
   "source": [
    "## Plot Low-Dimensional Embeddings\n",
    "\n",
    "You should see the targeted content bridges the topic and the user description.  This is most clear in the UMAP embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rxzOXb79wWhh",
   "metadata": {
    "id": "rxzOXb79wWhh"
   },
   "outputs": [],
   "source": [
    "embedding_type = 'umap'\n",
    "s = 250\n",
    "\n",
    "#plot the user description embedding\n",
    "sns.scatterplot(x=f'target_{embedding_type}_x',\n",
    "                y=f'target_{embedding_type}_y',\n",
    "                data=df_targets, hue='description',\n",
    "                marker = 'x',\n",
    "                s = s)\n",
    "\n",
    "#plot the content embedding\n",
    "sns.scatterplot(x=f'content_{embedding_type}_x',\n",
    "                y=f'content_{embedding_type}_y',\n",
    "                data=df_targets, hue='description',\n",
    "                marker = 'd',\n",
    "                s = s)\n",
    "\n",
    "#plot the topic embedding\n",
    "xy = v_umap if embedding_type == 'umap' else v_pca\n",
    "\n",
    "plt.scatter(xy[0], xy[1], color='black',\n",
    "            marker = 'd', s=2*s, label = 'Topic')\n",
    "\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Q7LPDThEqTgd",
   "metadata": {
    "id": "Q7LPDThEqTgd"
   },
   "source": [
    "# Targeting Content Based on User Tweets\n",
    "\n",
    "We do not need to provide descriptions of our target users.  We can just provide the tweets they posted on social media.  The AI will figure out how to persuade them based on their tweets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pBUmGs6zqWqs",
   "metadata": {
    "id": "pBUmGs6zqWqs"
   },
   "source": [
    "## Load a User's Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "Zl2FbVBrqYqO",
   "metadata": {
    "id": "Zl2FbVBrqYqO"
   },
   "outputs": [],
   "source": [
    "df_tweets = pd.read_csv('data/tweets_TwExportly_sentiments.csv')\n",
    "df_tweets.screen_name.unique()\n",
    "\n",
    "screen_names = ['1future', 'elonmusk',\n",
    "                'kamalaharris',\n",
    "                'StephenCurry30']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ZuByc3npqZGL",
   "metadata": {
    "id": "ZuByc3npqZGL"
   },
   "source": [
    "## Generate Targeted Tweet Based on User Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "WbqL6mkZqcdV",
   "metadata": {
    "id": "WbqL6mkZqcdV"
   },
   "outputs": [],
   "source": [
    "content = \"tweet\"\n",
    "\n",
    "instructions = f'''You will be given a tweets posted by a person.\n",
    "Create a {content} that will convence them to support: {topic}.\n",
    "Dont directly mention the information about the target in the message.\n",
    "Be more subtle as that makes the persuasion more effective. '''\n",
    "\n",
    "nsamples = 100\n",
    "for screen_name in screen_names:\n",
    "  df = df_tweets[df_tweets.screen_name == screen_name].sample(nsamples).copy()\n",
    "  tweets = \"\\n\".join(df.text.tolist())\n",
    "  prompt = f\"Tweets of person: {tweets}\"\n",
    "  print(f\"\\n{screen_name}\")\n",
    "  tweet = get_completion(prompt, instructions, client, MODEL)\n",
    "  display_tweet(tweet, screen_name);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "QDOusJYJqdNT",
   "metadata": {
    "id": "QDOusJYJqdNT"
   },
   "source": [
    "## Generate Targeted Image Content Based on Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "i74H_luHqilx",
   "metadata": {
    "id": "i74H_luHqilx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1future\n",
      "\n",
      "elonmusk\n",
      "\n",
      "kamalaharris\n",
      "\n",
      "StephenCurry30\n"
     ]
    }
   ],
   "source": [
    "content = \"description of an image to be posted to Instagram.\"\n",
    "\n",
    "instructions = f'''You will be given a tweets posted by a person.\n",
    "Convince them to support {topic} with a {content}.\n",
    "Dont directly mention the information about the target in the message.\n",
    "Be more subtle as that makes the persuasion more effective. '''\n",
    "\n",
    "nsamples = 100\n",
    "for screen_name in screen_names:\n",
    "  df = df_tweets[df_tweets.screen_name == screen_name].sample(nsamples).copy()\n",
    "  tweets = \"\\n\".join(df.text.tolist())\n",
    "  prompt = f\"Tweets of person: {tweets}\"\n",
    "  print(f\"\\n{screen_name}\")\n",
    "  image_prompt = get_completion(prompt, instructions,client,MODEL)\n",
    "  image_url, revised_prompt = generate_image(image_prompt)\n",
    "\n",
    "  instructions_caption = f'''Write an Instagram caption for this image\n",
    "  that will persuade a person with these tweets:<{tweets}>,\\n\n",
    "  to support {topic}.  Return only the caption.'''\n",
    "\n",
    "  caption = generate_image_description(image_urls, instructions_caption)\n",
    "\n",
    "\n",
    "  print(f\"\\n{tr.fill(image_prompt)}\")\n",
    "  display_IG(caption, image_url, screen_name)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "LQqbaoJVYfAZ",
   "metadata": {
    "id": "LQqbaoJVYfAZ"
   },
   "source": [
    "# Targeting Video Content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "X79jK72hFp80",
   "metadata": {
    "id": "X79jK72hFp80"
   },
   "source": [
    "## Choose a Target\n",
    "\n",
    "We have a few targets with descriptions in `df_targets` and we have tweets of users in `df_tweets`.  Choose someone from these datasets to be the target user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "70-JLg5JFsDK",
   "metadata": {
    "id": "70-JLg5JFsDK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1future\n"
     ]
    }
   ],
   "source": [
    "TARGET = 'tweets'\n",
    "\n",
    "\n",
    "#target from df_tweets\n",
    "if TARGET == 'tweets':\n",
    "  df_tweets = pd.read_csv('data/tweets_TwExportly_sentiments.csv')\n",
    "  screen_name = '1future'\n",
    "  nsamples = 100\n",
    "  df = df_tweets[df_tweets.screen_name==screen_name].sample(nsamples)\n",
    "  description = \"\".join(df.text.tolist())\n",
    "  print(f\"{screen_name}\")\n",
    "\n",
    "else:\n",
    "  #target from df_targets\n",
    "  description = df_targets.loc[0,'description']\n",
    "  print(f\"{tr.fill(description)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "UhbCBxRMl4lq",
   "metadata": {
    "id": "UhbCBxRMl4lq"
   },
   "source": [
    "## Write Script of Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jyN9sCTsY152",
   "metadata": {
    "id": "jyN9sCTsY152"
   },
   "outputs": [],
   "source": [
    "instructions = f'''You will be given tweets posted by a target user.\n",
    "You will convince this person to support {topic} by creating a TikTok video\n",
    "with 3 scenes.\n",
    "Write a script for this video and the voice narration for each scene.\n",
    "Your script format should be a list of JSON objects\n",
    "with keys \"scene\" (scene number) and \"description\" (description of scene),\n",
    "and \"narration\" (narration of scene).'''\n",
    "\n",
    "\n",
    "script = get_completion(description, instructions,client,MODEL)\n",
    "df_script = pd.read_json(script.replace(\"json\",'').replace(\"`\",\"\"))\n",
    "df_script.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ZZR9eBTHl9O_",
   "metadata": {
    "id": "ZZR9eBTHl9O_"
   },
   "source": [
    "## Create Images for Each Scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Cfo19fRGZdAL",
   "metadata": {
    "id": "Cfo19fRGZdAL"
   },
   "outputs": [],
   "source": [
    "for index, row in df_script.iterrows():\n",
    "  scene = row['scene']\n",
    "  description = row['description']\n",
    "  narration = row['narration']\n",
    "  image_url, revised_prompt = generate_image(description)\n",
    "  print(image_url)\n",
    "  display_IG(narration, image_url)\n",
    "  df_script.loc[index,'image_url'] = image_url\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dx8Me81KboC9",
   "metadata": {
    "id": "dx8Me81KboC9"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
