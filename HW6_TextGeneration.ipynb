{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vUOKSuOWzt3u"
   },
   "source": [
    "# Homework 6 - Text Generation\n",
    "\n",
    "This notebook provides some skeleton code to get you started on the homework. Add in your own code and markdown cells to answer the homework questions. If you want to submit the notebook as a PDF, make sure your code and markdowns are clear and concise to make grading easy for the TAs.\n",
    "\n",
    "This notebook can be opened in Colab\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/zlisto/social_media_analytics/blob/main/HW6_TextGeneration.ipynb)\n",
    "\n",
    "\n",
    "Before starting, select \"Runtime->Factory reset runtime\" to start with your directories and environment in the base state.\n",
    "\n",
    "If you want to save changes to the notebook, select \"File->Save a copy in Drive\" from the top menu in Colab. This will save the notebook in your Google Drive.\n",
    "\n",
    "For all plots, make sure your axes have nice labels with easy to read fontsizes, otherwise points will be deducted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tZ2fpQvAzt30"
   },
   "source": [
    "# Clones, Installs, and Imports\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xMPLJonkzt3-"
   },
   "source": [
    "# Problem 1. (34 points) User Tweet Generation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YAAjjL36zt3_"
   },
   "source": [
    "## (6 points) 1. Load Data\n",
    "\n",
    "Load the file `\"data/tweets_Twexportly.csv\"` into a dataframe `df_all`.  Remove any rows where the `client` column contains the string `\"Twitter for Advertisers\"`.  Then add a column to `df_all` called `engagement` which is `favorite_count` divided by `like_count`.  Print out the head of `df_all`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k_-pQwZWF-ma"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mH29LYShl8_V"
   },
   "source": [
    "## (6 points) 2. Select a Screen Name and Keep Only Tweets With Valid Engagement\n",
    "\n",
    "Create a dataframe called `df` which is all rows in `df_all` where the `screen_name` is `\"dunemovie\"`.  Some of these tweets do not have a value for `view_count` so we cannot measure their engagement.  We will have to ignore these tweets for this problem.\n",
    "\n",
    "Remove from `df` any rows where `engagement` is NA (you can do this with the `isna()` function).  Then sort `df` by engagement in descending order so the most engaging tweets are first. Print out the length of your cleaned up `df`.  Also print out the head of the `\"engagement\"` and `\"text\"` columns  `df` (only these two columns, not all the columns).  These are the most engaging tweets and their engagement scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VkSXwoEoF9ty"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p5Rn-qUuu4gh"
   },
   "source": [
    "## (10 points) 3. Analyze Engagement with AI\n",
    "\n",
    "Create  `instructions` which contains the top 10 lowest and top 10 highest engagement tweets of `\"screen_name\"`.  Create `prompt` which tells the AI return to you an `analysis` of how the high engagement tweets differ from low engagement tweets.  Also have it show you specific examples of high and low engagement tweets.  Have the AI return the `analysis` as an HTML file.  Display your `analysis` HTML output using the `display` and `HTML` functions so it is easy to read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3gpEQ5IkGA8a"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2fJXgOUGvjS5"
   },
   "source": [
    "## (12 points) 4. Enhance Tweets with AI\n",
    "\n",
    "Take the 5 lowest engagement tweets and enhance them with the AI based on your `analysis` from the previous problem.  Put the `analysis`, along with the high and low engagement tweet samples in `instructions`.  Print out the original tweet and its `engagement` value (so we know you picked the low engagement tweets) and then below it print the enhanced tweet.  Make sure you put some kind of demarcation string (like `\"-\"*50`) between each group of tweets, put headers for the tweets like `\"Old Tweet\"` and `\"Enhanced Tweet\"`, and use the `fill` function so it is easier to read.  Using formatted strings, `sort_values` and a `for` loop might be handy here.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yPCXWgb4GCk0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6bk4ZzbxG2XP"
   },
   "source": [
    "# Problem 2. (53 points) Cluster Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JVdr4jbU0wCn"
   },
   "source": [
    "## (2 points) 1. Load Data\n",
    "\n",
    "Create a dataframe `df` that is the tweets of `\"dunemovie\"` with the tweet advertisements filtered out.  This is the same dataframe used in Problem 1. Print out the head of this dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0FoKScC-GEE1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "McnMPL9cw36-"
   },
   "source": [
    "## (10 points) 2. Embed Tweets\n",
    "\n",
    "Compute the OpenAI Embeddings of the tweets in `df` and then compute their UMAP two-dimensional embeddings.  Add these as columns `umap_x` and `umap_y` to `df`. After you do this, we recommend you save `df` to a file so you do not have to compute the embeddings again (it takes about 2 minutes for 399 tweets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ETjAxn_GGFEu"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ws18DzQtxWt0"
   },
   "source": [
    "## (10 points) 3. Cluster Tweets\n",
    "\n",
    "Cluster the tweets using k-means applied to the UMAP embeddings.  Use `k=5` clusters.  Save the cluster labels as a column `\"cluster\"` in `df`.  Make a `countplot` of the number of tweets in each cluster with proper axis labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "isXVAT3ZGGpO"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OjIUXs7ZzeNk"
   },
   "source": [
    "## (8 points) 4. Scatter Plot Embeddings\n",
    "\n",
    "Make an interactive scatterplot of the UMAP embeddings using the `plotly.express.scatter` function.  Color the markers by their `cluster` and make the marker size proportional to their `engagement`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ONwZMvxvGISG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uds1zxFZJ4d-"
   },
   "source": [
    "## (8 points) 5. Cluster Engagement\n",
    "\n",
    "Compute the engagement for each cluster using the Binomial Engagement model.  You can use the `groupby` function for this.\n",
    "\n",
    "Make a bar plot of the `\"engagement\"` for each cluster,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NaDzQOJdGLtY"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xO9NiEQytfxG"
   },
   "source": [
    "## (7 points) 6. Analyze High Engagement Cluster\n",
    "\n",
    "Find the cluster with the highest engagement and print out its label and exact engagement value.  Then put a sample of 10 tweets from this cluster in a prompt to the AI and have it provide an analysis of the common theme in the cluster.  Print out the analysis using the `fill` function so it is easy to read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VgOWVS6vGMxJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hZDcw8BJvo_-"
   },
   "source": [
    "## (8 points) 6. Generate Tweets from High Engagement Cluster with AI\n",
    "\n",
    "Use the AI to generate three tweets that reflects the style and topic of the highest engagement cluster's tweets.  Put 10 tweets from the cluster in the `instructions` and have the `prompt` tell the AI to generate the tweet similar to these samples.  Print out the three generated tweets, making sure there is spacing and demarcation between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UEbPWy1BGNtI"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "06lJx0Df0Icq"
   },
   "source": [
    "# Problem 3. (13 points) Customer Service Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xLFt9ThG0N7s"
   },
   "source": [
    "## (2 points) 1. Load Data\n",
    "\n",
    "Load the data in `\"data/tweet_complaints_AmericanAir.csv\"` into a dataframe `df_complaints`.  Print the head of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6ktVAy-DGO56"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U6Q-lopj0mE2"
   },
   "source": [
    "## (4 points) 2. Customer Service Instructions\n",
    "\n",
    "Create a string `instructions` that tells the AI to address the customer complaints. Create another string `instructions_style` that has information on the identity and style of the AI (name, background, speaking style, etc.  ).  Please be creative with the AI identity.  Add `instructions_style` to `instructions`. Print out `instructions` with the `fill` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xevv1l5lOBei"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NwVLQ-xH1Lsr"
   },
   "source": [
    "## (7 points) 3. Reply to Complaints with AI\n",
    "\n",
    "Use `instructions` and the AI to generate a tweet to reply to each complaint in `df_complaints`.  You can put the complaint in the `prompt`.  Print the complaint tweet and the AI's response tweet below it.  Make sure you use the `fill` function and also put some space or new lines between each complaint/response pair so it is easy to read.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UJQI5eP-GQnj"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
